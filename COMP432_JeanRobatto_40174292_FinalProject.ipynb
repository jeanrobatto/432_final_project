{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOYGrWPMegaQynuKpYazSrs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeanrobatto/COMP432-FinalProject/blob/main/COMP432_JeanRobatto_40174292_FinalProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **COMP-432 - Final Project - EEG Decoding**"
      ],
      "metadata": {
        "id": "Vc-uocaD8L9S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Author: Jean Robatto - 40174292"
      ],
      "metadata": {
        "id": "U_zS27Dq8qr3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Abstract**"
      ],
      "metadata": {
        "id": "Zd4cBl5C8fA1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Abstract here. Give an executive summary of your project: goal, methods, results, conclusions. Usually no more than 200 words."
      ],
      "metadata": {
        "id": "ysmAUu058nt7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Introduction**"
      ],
      "metadata": {
        "id": "XPkUuRH28z4P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here you have to explain the problem that you are solving. Explain why it is important, and what are the main challenges. Mention previous attempts (add papers as references) to solve it. Mainly focus on the techniques closely related to our approach. Briefly describe your approach and explain why it is promising for solving the addressed problem. Mention the dataset and the main results achieved.\n",
        "In this section, you can add text and figures."
      ],
      "metadata": {
        "id": "uQuVcSwg83-P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Methodology**"
      ],
      "metadata": {
        "id": "PfQuCLwE9BFT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Describe the important steps you took to achieve your goal. Focus more on the most important steps (preprocessing, extra features, model aspects) that turned out to be important. Mention the original aspects of the project and state how they relate to existing work.\n",
        "In this section, you can add text and figures. For instance, it is strongly suggested to add a picture of the best machine learning model that you implemented to solve your problem (and describe it)."
      ],
      "metadata": {
        "id": "sLxdhqVO9E1a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stuff needed to run the code - benchmarks and my own python repo"
      ],
      "metadata": {
        "id": "Sz1DpzdR-6m5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkw1jVAnpBQ9"
      },
      "source": [
        "## **Prerequisites**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download SpeechBrain-MOABB"
      ],
      "metadata": {
        "id": "D7Wofz40AUGz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SpeechBrain-MOABB can be downloaded from the GitHub repository listed below."
      ],
      "metadata": {
        "id": "8vpod0AgBJCl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Source: https://github.com/speechbrain/benchmarks\n",
        "\n",
        "%%capture\n",
        "%cd /content/\n",
        "\n",
        "!git clone https://github.com/speechbrain/benchmarks\n",
        "%cd /content/benchmarks\n",
        "!git checkout eeg\n",
        "\n",
        "%cd /content/benchmarks/benchmarks/MOABB\n",
        "!pip install -r extra-requirements.txt # Install additional dependencies\n",
        "\n",
        "%cd /content/"
      ],
      "metadata": {
        "id": "4jMh4ycXBcN9"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install SpeechBrain and SpeechBrain-MOABB requirements, and install SpeechBrain"
      ],
      "metadata": {
        "id": "h01EibZ4BtbA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Source: https://github.com/speechbrain/benchmarks\n",
        "\n",
        "%%capture\n",
        "# Clone SpeechBrain repository (development branch)\n",
        "%cd /content/\n",
        "!git clone https://github.com/speechbrain/speechbrain/\n",
        "%cd /content/speechbrain/\n",
        "\n",
        "# Install required dependencies\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "# Install SpeechBrain in editable mode\n",
        "!pip install -e .\n",
        "\n",
        "%cd /content/\n"
      ],
      "metadata": {
        "id": "81vpp8dhCDLN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download the helper Python library"
      ],
      "metadata": {
        "id": "Zp_3xp9qCHoH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Source: https://github.com/jeanrobatto/COMP432-FinalProject\n",
        "\n",
        "%%capture\n",
        "%cd /content/\n",
        "\n",
        "!git clone https://github.com/jeanrobatto/COMP432-FinalProject\n",
        "%cd /content/COMP432-FinalProject\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "%cd /content/"
      ],
      "metadata": {
        "id": "wFKGmlh9CPXa"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set necessary ENV variables in runtime env"
      ],
      "metadata": {
        "id": "galS_8gK6DwB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!export ORION_DB_ADDRESS=results/MotorImagery/BNCI2014001/EEGNet/hopt/EEGNet_BNCI2014001_hopt.pkl\n",
        "!export ORION_DB_TYPE=pickleddb"
      ],
      "metadata": {
        "id": "7RF2tLeJ6Iwm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test installations completed successfully"
      ],
      "metadata": {
        "id": "rg04OYiIDS_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version\n",
        "\n",
        "%cd /content/COMP432-FinalProject/src/\n",
        "!python .\n",
        "\n",
        "# Copy quick 1 epoch config file to test train.py script\n",
        "!cp /content/COMP432-FinalProject/yaml/EEG_Net_QUICK_TEST.yaml /content/benchmarks/benchmarks/MOABB/hparams/MotorImagery/BNCI2014001/EEG_Net_QUICK_TEST.yaml\n",
        "\n",
        "%cd /content/benchmarks/benchmarks/MOABB/\n",
        "!python ./train.py hparams/MotorImagery/BNCI2014001/EEG_Net_QUICK_TEST.yaml --data_folder=eeg_data --cached_data_folder=eeg_pickled_data --output_folder=results/MotorImagery/BNCI2014001/ --target_subject_idx=0 --target_session_idx=1 --data_iterator_name=leave-one-session-out;\n",
        "!echo 'Environment setup successful!'"
      ],
      "metadata": {
        "id": "-IxkU40YDbXh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb01a95a-08b4-49f7-87d0-1a69f6af8408"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n",
            "/content/COMP432-FinalProject/src\n",
            "(Custom helper lib) Hello, world!\n",
            "/content/benchmarks/benchmarks/MOABB\n",
            "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.pick_types is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
            "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.pick_channels_regexp is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
            "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.channel_type is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
            "2024-04-05 20:36:07.512703: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-05 20:36:07.512756: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-05 20:36:07.514048: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-05 20:36:07.521330: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-04-05 20:36:08.521602: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/moabb/pipelines/__init__.py:26: ModuleNotFoundError: Tensorflow is not installed. You won't be able to use these MOABB pipelines if you attempt to do so.\n",
            "  warn(\n",
            "To use the get_shape_from_baseconcar, InputShapeSetterEEG, BraindecodeDatasetLoaderyou need to install `braindecode`.`pip install braindecode` or Please refer to `https://braindecode.org`.\n",
            "BNCI2014001 has been renamed to BNCI2014_001. BNCI2014001 will be removed in version 1.1.\n",
            "The dataset class name 'BNCI2014001' must be an abbreviation of its code 'BNCI2014-001'. See moabb.datasets.base.is_abbrev for more information.\n",
            "Prepare dataset iterators...\n",
            "Using cached dataset at: eeg_pickled_data/MOABB_pickled/BNCI2014-001/0125_0.13-46.0/sub-001.pkl\n",
            "Skipping data saving, a cached dataset was found at eeg_pickled_data/MOABB_pickled/BNCI2014-001/0125_0.13-46.0/sub-001.pkl\n",
            "Session/sessions used as training and validation set: ['0train']\n",
            "Session used as test set: ['1test']\n",
            "Validation indices: [3, 16, 38, 58, 79, 110, 130, 152, 176, 197, 223, 240, 270, 287, 2, 20, 42, 72, 90, 112, 129, 156, 170, 201, 210, 242, 257, 286, 1, 33, 43, 62, 80, 111, 137, 150, 177, 199, 230, 245, 262, 284, 0, 25, 39, 66, 86, 107, 119, 157, 173, 196, 214, 241, 250, 276]\n",
            "Sampling channels: ['Fz', 'FC3', 'FC1', 'FCz', 'FC2', 'FC4', 'C3', 'C1', 'Cz', 'C2', 'C4', 'CP1', 'CPz', 'CP2', 'P1', 'Pz', 'P2']\n",
            "Sampling channels: ['Fz', 'FC3', 'FC1', 'FCz', 'FC2', 'FC4', 'C3', 'C1', 'Cz', 'C2', 'C4', 'CP1', 'CPz', 'CP2', 'P1', 'Pz', 'P2']\n",
            "Sampling channels: ['Fz', 'FC3', 'FC1', 'FCz', 'FC2', 'FC4', 'C3', 'C1', 'Cz', 'C2', 'C4', 'CP1', 'CPz', 'CP2', 'P1', 'Pz', 'P2']\n",
            "BNCI2014001 has been renamed to BNCI2014_001. BNCI2014001 will be removed in version 1.1.\n",
            "The dataset class name 'BNCI2014001' must be an abbreviation of its code 'BNCI2014-001'. See moabb.datasets.base.is_abbrev for more information.\n",
            "speechbrain.core - Beginning experiment!\n",
            "speechbrain.core - Experiment folder: results/MotorImagery/BNCI2014001/leave-one-session-out/sub-001/1test\n",
            "__main__ - Experiment directory: results/MotorImagery/BNCI2014001/leave-one-session-out/sub-001/1test\n",
            "__main__ - Input shape: torch.Size([500, 17, 1])\n",
            "__main__ - Training set avg value: 4.9769884213901605e-08\n",
            "__main__ - Number of examples: 232 (training), 56 (validation), 288 (test)\n",
            "speechbrain.core - Gradscaler enabled: False. Using precision: fp32.\n",
            "speechbrain.core - MOABBBrain Model Statistics:\n",
            "* Total Number of Trainable Parameters: 145.9k\n",
            "* Total Number of Parameters: 145.9k\n",
            "* Trainable Parameters represent 100.0000% of the total size.\n",
            "==========================================================================================\n",
            "Layer (type:depth-idx)                   Output Shape              Param #\n",
            "==========================================================================================\n",
            "EEGNet                                   [1, 4]                    --\n",
            "├─Sequential: 1-1                        [1, 17, 1, 428]           --\n",
            "│    └─Conv2d: 2-1                       [1, 500, 17, 61]          --\n",
            "│    │    └─Conv2d: 3-1                  [1, 61, 500, 17]          3,111\n",
            "│    └─BatchNorm2d: 2-2                  [1, 500, 17, 61]          --\n",
            "│    │    └─BatchNorm2d: 3-2             [1, 61, 17, 500]          122\n",
            "│    └─Conv2d: 2-3                       [1, 500, 1, 244]          --\n",
            "│    │    └─Conv2d: 3-3                  [1, 244, 500, 1]          4,148\n",
            "│    └─BatchNorm2d: 2-4                  [1, 500, 1, 244]          --\n",
            "│    │    └─BatchNorm2d: 3-4             [1, 244, 1, 500]          488\n",
            "│    └─ELU: 2-5                          [1, 500, 1, 244]          --\n",
            "│    └─Pooling2d: 2-6                    [1, 125, 1, 244]          --\n",
            "│    │    └─AvgPool2d: 3-5               [1, 244, 125, 1]          --\n",
            "│    └─Dropout: 2-7                      [1, 125, 1, 244]          --\n",
            "│    └─Conv2d: 2-8                       [1, 125, 1, 244]          --\n",
            "│    │    └─Conv2d: 3-6                  [1, 244, 125, 1]          3,660\n",
            "│    └─Conv2d: 2-9                       [1, 125, 1, 428]          --\n",
            "│    │    └─Conv2d: 3-7                  [1, 428, 125, 1]          104,432\n",
            "│    └─BatchNorm2d: 2-10                 [1, 125, 1, 428]          --\n",
            "│    │    └─BatchNorm2d: 3-8             [1, 428, 1, 125]          856\n",
            "│    └─ELU: 2-11                         [1, 125, 1, 428]          --\n",
            "│    └─Pooling2d: 2-12                   [1, 17, 1, 428]           --\n",
            "│    │    └─AvgPool2d: 3-9               [1, 428, 17, 1]           --\n",
            "│    └─Dropout: 2-13                     [1, 17, 1, 428]           --\n",
            "├─Sequential: 1-2                        [1, 4]                    --\n",
            "│    └─Flatten: 2-14                     [1, 7276]                 --\n",
            "│    └─Linear: 2-15                      [1, 4]                    --\n",
            "│    │    └─Linear: 3-10                 [1, 4]                    29,108\n",
            "│    └─LogSoftmax: 2-16                  [1, 4]                    --\n",
            "==========================================================================================\n",
            "Total params: 145,925\n",
            "Trainable params: 145,925\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (M): 42.06\n",
            "==========================================================================================\n",
            "Input size (MB): 0.03\n",
            "Forward/backward pass size (MB): 11.35\n",
            "Params size (MB): 0.58\n",
            "Estimated Total Size (MB): 11.97\n",
            "==========================================================================================\n",
            "speechbrain.utils.epoch_loop - Going into epoch 1\n",
            "speechbrain.nnet.schedulers - Changing lr from 5.2e-05 to 5.5e-05\n",
            "speechbrain.utils.train_logger - epoch: 1, lr: 4.83e-05 - train loss: 1.37 - valid loss: 1.39, valid f1: 1.75e-01, valid acc: 2.86e-01, valid cm: [[13  0  0  1]\n",
            " [12  0  0  2]\n",
            " [13  0  0  1]\n",
            " [11  0  0  3]]\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/MotorImagery/BNCI2014001/leave-one-session-out/sub-001/1test/save/CKPT+2024-04-05+20-36-13+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/MotorImagery/BNCI2014001/leave-one-session-out/sub-001/1test/save/CKPT+2024-04-05+20-35-22+00\n",
            "speechbrain.utils.checkpoints - Loading a checkpoint from results/MotorImagery/BNCI2014001/leave-one-session-out/sub-001/1test/save/CKPT+2024-04-05+20-36-13+00\n",
            "speechbrain.utils.train_logger - epoch loaded: 1 - test loss: 1.39, test f1: 1.55e-01, test acc: 2.78e-01, test cm: [[10 62  0  0]\n",
            " [ 2 70  0  0]\n",
            " [13 59  0  0]\n",
            " [ 8 64  0  0]]\n",
            "speechbrain.utils.checkpoints - Loading a checkpoint from results/MotorImagery/BNCI2014001/leave-one-session-out/sub-001/1test/save/CKPT+2024-04-05+20-36-13+00\n",
            "speechbrain.utils.train_logger - epoch loaded: 1 - test loss: 1.39, test f1: 1.50e-01, test acc: 2.68e-01, test cm: [[ 2 12  0  0]\n",
            " [ 1 13  0  0]\n",
            " [ 3 11  0  0]\n",
            " [ 4 10  0  0]]\n",
            "Environment setup successful!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Experimental Setup**"
      ],
      "metadata": {
        "id": "9m2omL-K9ICn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Describe the datasets used for your experiments. List the machine learning techniques used to solve your problem and report the corresponding hyperparameters.\n",
        "In this section, you can add text, tables, and figures."
      ],
      "metadata": {
        "id": "NNoBK8FC9L0z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Experimental Results**"
      ],
      "metadata": {
        "id": "Zsn-yRDy9OXq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Describe here the main experimental results. Critically discuss them. Compare them with results available in the literature (if applicable).\n",
        "In this section, you can add text and figures, tables, plots, and code. Make sure the code is runnable and replicable."
      ],
      "metadata": {
        "id": "EquR0ftO9OMp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Conclusions**"
      ],
      "metadata": {
        "id": "FLG5VDWL9Vt5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summarize what you could and could not conclude based on your experiments. In this section, you can add text."
      ],
      "metadata": {
        "id": "7ukqW8Ki9YXs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **References**"
      ],
      "metadata": {
        "id": "UhO6Rukr9Zjd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can add here the citations of books, websites, or academic papers, etc."
      ],
      "metadata": {
        "id": "VMs3YCjk9cyx"
      }
    }
  ]
}