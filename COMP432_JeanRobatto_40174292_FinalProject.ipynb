{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOMfglKX75kZQjuFY/2X91b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeanrobatto/COMP432-FinalProject/blob/main/COMP432_JeanRobatto_40174292_FinalProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **COMP-432 - Final Project - EEG Decoding**"
      ],
      "metadata": {
        "id": "Vc-uocaD8L9S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Author: Jean Robatto - 40174292"
      ],
      "metadata": {
        "id": "U_zS27Dq8qr3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Abstract**"
      ],
      "metadata": {
        "id": "Zd4cBl5C8fA1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Abstract here. Give an executive summary of your project: goal, methods, results, conclusions. Usually no more than 200 words."
      ],
      "metadata": {
        "id": "ysmAUu058nt7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Introduction**"
      ],
      "metadata": {
        "id": "XPkUuRH28z4P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here you have to explain the problem that you are solving. Explain why it is important, and what are the main challenges. Mention previous attempts (add papers as references) to solve it. Mainly focus on the techniques closely related to our approach. Briefly describe your approach and explain why it is promising for solving the addressed problem. Mention the dataset and the main results achieved.\n",
        "In this section, you can add text and figures."
      ],
      "metadata": {
        "id": "uQuVcSwg83-P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Methodology**"
      ],
      "metadata": {
        "id": "PfQuCLwE9BFT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Describe the important steps you took to achieve your goal. Focus more on the most important steps (preprocessing, extra features, model aspects) that turned out to be important. Mention the original aspects of the project and state how they relate to existing work.\n",
        "In this section, you can add text and figures. For instance, it is strongly suggested to add a picture of the best machine learning model that you implemented to solve your problem (and describe it)."
      ],
      "metadata": {
        "id": "sLxdhqVO9E1a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stuff needed to run the code - benchmarks and my own python repo"
      ],
      "metadata": {
        "id": "Sz1DpzdR-6m5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkw1jVAnpBQ9"
      },
      "source": [
        "## **Prerequisites**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download SpeechBrain-MOABB"
      ],
      "metadata": {
        "id": "D7Wofz40AUGz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SpeechBrain-MOABB can be downloaded from the GitHub repository listed below."
      ],
      "metadata": {
        "id": "8vpod0AgBJCl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Source: https://github.com/speechbrain/benchmarks\n",
        "\n",
        "%%capture\n",
        "%cd /content/\n",
        "\n",
        "!git clone https://github.com/speechbrain/benchmarks\n",
        "%cd /content/benchmarks\n",
        "!git checkout eeg\n",
        "\n",
        "%cd /content/benchmarks/benchmarks/MOABB\n",
        "!pip install -r extra-requirements.txt # Install additional dependencies\n",
        "\n",
        "%cd /content/"
      ],
      "metadata": {
        "id": "4jMh4ycXBcN9"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install SpeechBrain and SpeechBrain-MOABB requirements, and install SpeechBrain"
      ],
      "metadata": {
        "id": "h01EibZ4BtbA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Source: https://github.com/speechbrain/benchmarks\n",
        "\n",
        "%%capture\n",
        "# Clone SpeechBrain repository (development branch)\n",
        "%cd /content/\n",
        "!git clone https://github.com/speechbrain/speechbrain/\n",
        "%cd /content/speechbrain/\n",
        "\n",
        "# Install required dependencies\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "# Install SpeechBrain in editable mode\n",
        "!pip install -e .\n",
        "\n",
        "%cd /content/\n"
      ],
      "metadata": {
        "id": "81vpp8dhCDLN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download the helper Python library"
      ],
      "metadata": {
        "id": "Zp_3xp9qCHoH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Source: https://github.com/jeanrobatto/COMP432-FinalProject\n",
        "\n",
        "%%capture\n",
        "%cd /content/\n",
        "\n",
        "!git clone https://github.com/jeanrobatto/COMP432-FinalProject\n",
        "%cd /content/COMP432-FinalProject\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "%cd /content/"
      ],
      "metadata": {
        "id": "wFKGmlh9CPXa"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set necessary ENV variables in runtime env"
      ],
      "metadata": {
        "id": "galS_8gK6DwB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!export ORION_DB_ADDRESS=results/MotorImagery/BNCI2014001/EEGNet/hopt/EEGNet_BNCI2014001_hopt.pkl\n",
        "!export ORION_DB_TYPE=pickleddb"
      ],
      "metadata": {
        "id": "7RF2tLeJ6Iwm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test installations completed successfully"
      ],
      "metadata": {
        "id": "rg04OYiIDS_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version\n",
        "\n",
        "%cd /content/COMP432-FinalProject/src/\n",
        "!python .\n",
        "\n",
        "# Copy quick 1 epoch config file to test train.py script\n",
        "!cp /content/COMP432-FinalProject/yaml/EEG_Net_QUICK_TEST.yaml /content/benchmarks/benchmarks/MOABB/hparams/MotorImagery/BNCI2014001/EEG_Net_QUICK_TEST.yaml\n",
        "\n",
        "%cd /content/benchmarks/benchmarks/MOABB/\n",
        "!echo 'Training dummy model (30s)...'\n",
        "!python ./train.py hparams/MotorImagery/BNCI2014001/EEG_Net_QUICK_TEST.yaml --data_folder=eeg_data --cached_data_folder=eeg_pickled_data --output_folder=results/MotorImagery/BNCI2014001/ --target_subject_idx=0 --target_session_idx=1 --data_iterator_name=leave-one-session-out &> /dev/null\n",
        "!echo 'Training successful'\n",
        "!echo 'Environment setup successful'"
      ],
      "metadata": {
        "id": "-IxkU40YDbXh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4208ddda-ad0e-45fe-b614-55c10ce364a8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n",
            "/content/COMP432-FinalProject/src\n",
            "(Custom helper lib) Hello, world!\n",
            "/content/benchmarks/benchmarks/MOABB\n",
            "Training dummy model...\n",
            "Training successful\n",
            "Environment setup successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Experimental Setup**"
      ],
      "metadata": {
        "id": "9m2omL-K9ICn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Describe the datasets used for your experiments. List the machine learning techniques used to solve your problem and report the corresponding hyperparameters.\n",
        "In this section, you can add text, tables, and figures."
      ],
      "metadata": {
        "id": "NNoBK8FC9L0z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Experimental Results**"
      ],
      "metadata": {
        "id": "Zsn-yRDy9OXq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Describe here the main experimental results. Critically discuss them. Compare them with results available in the literature (if applicable).\n",
        "In this section, you can add text and figures, tables, plots, and code. Make sure the code is runnable and replicable."
      ],
      "metadata": {
        "id": "EquR0ftO9OMp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Conclusions**"
      ],
      "metadata": {
        "id": "FLG5VDWL9Vt5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summarize what you could and could not conclude based on your experiments. In this section, you can add text."
      ],
      "metadata": {
        "id": "7ukqW8Ki9YXs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **References**"
      ],
      "metadata": {
        "id": "UhO6Rukr9Zjd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can add here the citations of books, websites, or academic papers, etc."
      ],
      "metadata": {
        "id": "VMs3YCjk9cyx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scratchpad"
      ],
      "metadata": {
        "id": "boLahRTCKToA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Code to try out various models\n",
        "\n",
        "%cd /content/benchmarks/benchmarks/MOABB/\n",
        "!python ./train.py hparams/MotorImagery/BNCI2014001/EEGNet.yaml --data_folder=eeg_data --cached_data_folder=eeg_pickled_data --output_folder=results/MotorImagery/BNCI2014001/ --target_subject_idx=0 --target_session_idx=1 --data_iterator_name=leave-one-session-out\n",
        "#!python utils/parse_results.py results/MotorImagery/BNCI2014001 test_metrics.pkl acc loss f1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaEYSfmlKWlT",
        "outputId": "b43c6ea9-89b0-4460-dfdf-d1791460cb22"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/benchmarks/benchmarks/MOABB\n",
            "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.pick_types is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
            "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.pick_channels_regexp is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
            "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.channel_type is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
            "2024-04-06 01:26:56.340102: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-06 01:26:56.340156: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-06 01:26:56.341451: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-06 01:26:56.348593: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-04-06 01:26:57.355399: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/moabb/pipelines/__init__.py:26: ModuleNotFoundError: Tensorflow is not installed. You won't be able to use these MOABB pipelines if you attempt to do so.\n",
            "  warn(\n",
            "To use the get_shape_from_baseconcar, InputShapeSetterEEG, BraindecodeDatasetLoaderyou need to install `braindecode`.`pip install braindecode` or Please refer to `https://braindecode.org`.\n",
            "BNCI2014001 has been renamed to BNCI2014_001. BNCI2014001 will be removed in version 1.1.\n",
            "The dataset class name 'BNCI2014001' must be an abbreviation of its code 'BNCI2014-001'. See moabb.datasets.base.is_abbrev for more information.\n",
            "Prepare dataset iterators...\n",
            "Using cached dataset at: eeg_pickled_data/MOABB_pickled/BNCI2014-001/0125_0.13-46.0/sub-001.pkl\n",
            "Skipping data saving, a cached dataset was found at eeg_pickled_data/MOABB_pickled/BNCI2014-001/0125_0.13-46.0/sub-001.pkl\n",
            "Session/sessions used as training and validation set: ['0train']\n",
            "Session used as test set: ['1test']\n",
            "Validation indices: [3, 16, 38, 58, 79, 110, 130, 152, 176, 197, 223, 240, 270, 287, 2, 20, 42, 72, 90, 112, 129, 156, 170, 201, 210, 242, 257, 286, 1, 33, 43, 62, 80, 111, 137, 150, 177, 199, 230, 245, 262, 284, 0, 25, 39, 66, 86, 107, 119, 157, 173, 196, 214, 241, 250, 276]\n",
            "Sampling channels: ['Fz', 'FC3', 'FC1', 'FCz', 'FC2', 'FC4', 'C3', 'C1', 'Cz', 'C2', 'C4', 'CP1', 'CPz', 'CP2', 'P1', 'Pz', 'P2']\n",
            "Sampling channels: ['Fz', 'FC3', 'FC1', 'FCz', 'FC2', 'FC4', 'C3', 'C1', 'Cz', 'C2', 'C4', 'CP1', 'CPz', 'CP2', 'P1', 'Pz', 'P2']\n",
            "Sampling channels: ['Fz', 'FC3', 'FC1', 'FCz', 'FC2', 'FC4', 'C3', 'C1', 'Cz', 'C2', 'C4', 'CP1', 'CPz', 'CP2', 'P1', 'Pz', 'P2']\n",
            "BNCI2014001 has been renamed to BNCI2014_001. BNCI2014001 will be removed in version 1.1.\n",
            "The dataset class name 'BNCI2014001' must be an abbreviation of its code 'BNCI2014-001'. See moabb.datasets.base.is_abbrev for more information.\n",
            "speechbrain.core - Beginning experiment!\n",
            "speechbrain.core - Experiment folder: results/MotorImagery/BNCI2014001/leave-one-session-out/sub-001/1test\n",
            "__main__ - Experiment directory: results/MotorImagery/BNCI2014001/leave-one-session-out/sub-001/1test\n",
            "__main__ - Input shape: torch.Size([500, 17, 1])\n",
            "__main__ - Training set avg value: 4.9769884213901605e-08\n",
            "__main__ - Number of examples: 232 (training), 56 (validation), 288 (test)\n",
            "speechbrain.core - Gradscaler enabled: False. Using precision: fp32.\n",
            "speechbrain.core - MOABBBrain Model Statistics:\n",
            "* Total Number of Trainable Parameters: 145.9k\n",
            "* Total Number of Parameters: 145.9k\n",
            "* Trainable Parameters represent 100.0000% of the total size.\n",
            "==========================================================================================\n",
            "Layer (type:depth-idx)                   Output Shape              Param #\n",
            "==========================================================================================\n",
            "EEGNet                                   [1, 4]                    --\n",
            "├─Sequential: 1-1                        [1, 17, 1, 428]           --\n",
            "│    └─Conv2d: 2-1                       [1, 500, 17, 61]          --\n",
            "│    │    └─Conv2d: 3-1                  [1, 61, 500, 17]          3,111\n",
            "│    └─BatchNorm2d: 2-2                  [1, 500, 17, 61]          --\n",
            "│    │    └─BatchNorm2d: 3-2             [1, 61, 17, 500]          122\n",
            "│    └─Conv2d: 2-3                       [1, 500, 1, 244]          --\n",
            "│    │    └─Conv2d: 3-3                  [1, 244, 500, 1]          4,148\n",
            "│    └─BatchNorm2d: 2-4                  [1, 500, 1, 244]          --\n",
            "│    │    └─BatchNorm2d: 3-4             [1, 244, 1, 500]          488\n",
            "│    └─ELU: 2-5                          [1, 500, 1, 244]          --\n",
            "│    └─Pooling2d: 2-6                    [1, 125, 1, 244]          --\n",
            "│    │    └─AvgPool2d: 3-5               [1, 244, 125, 1]          --\n",
            "│    └─Dropout: 2-7                      [1, 125, 1, 244]          --\n",
            "│    └─Conv2d: 2-8                       [1, 125, 1, 244]          --\n",
            "│    │    └─Conv2d: 3-6                  [1, 244, 125, 1]          3,660\n",
            "│    └─Conv2d: 2-9                       [1, 125, 1, 428]          --\n",
            "│    │    └─Conv2d: 3-7                  [1, 428, 125, 1]          104,432\n",
            "│    └─BatchNorm2d: 2-10                 [1, 125, 1, 428]          --\n",
            "│    │    └─BatchNorm2d: 3-8             [1, 428, 1, 125]          856\n",
            "│    └─ELU: 2-11                         [1, 125, 1, 428]          --\n",
            "│    └─Pooling2d: 2-12                   [1, 17, 1, 428]           --\n",
            "│    │    └─AvgPool2d: 3-9               [1, 428, 17, 1]           --\n",
            "│    └─Dropout: 2-13                     [1, 17, 1, 428]           --\n",
            "├─Sequential: 1-2                        [1, 4]                    --\n",
            "│    └─Flatten: 2-14                     [1, 7276]                 --\n",
            "│    └─Linear: 2-15                      [1, 4]                    --\n",
            "│    │    └─Linear: 3-10                 [1, 4]                    29,108\n",
            "│    └─LogSoftmax: 2-16                  [1, 4]                    --\n",
            "==========================================================================================\n",
            "Total params: 145,925\n",
            "Trainable params: 145,925\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (M): 42.06\n",
            "==========================================================================================\n",
            "Input size (MB): 0.03\n",
            "Forward/backward pass size (MB): 11.35\n",
            "Params size (MB): 0.58\n",
            "Estimated Total Size (MB): 11.97\n",
            "==========================================================================================\n",
            "speechbrain.utils.epoch_loop - Going into epoch 1\n",
            "speechbrain.nnet.schedulers - Changing lr from 2.1e-05 to 2.2e-05\n",
            "speechbrain.utils.train_logger - epoch: 1, lr: 1.95e-05 - train loss: 1.39 - valid loss: 1.39, valid f1: 1.00e-01, valid acc: 2.50e-01, valid cm: [[14  0  0  0]\n",
            " [14  0  0  0]\n",
            " [14  0  0  0]\n",
            " [14  0  0  0]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 2\n",
            "speechbrain.nnet.schedulers - Changing lr from 4.2e-05 to 4.3e-05\n",
            "speechbrain.utils.train_logger - epoch: 2, lr: 4.03e-05 - train loss: 1.39 - valid loss: 1.39, valid f1: 1.00e-01, valid acc: 2.50e-01, valid cm: [[ 0  0 14  0]\n",
            " [ 0  0 14  0]\n",
            " [ 0  0 14  0]\n",
            " [ 0  0 14  0]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 3\n",
            "speechbrain.nnet.schedulers - Changing lr from 6.3e-05 to 6.4e-05\n",
            "speechbrain.utils.train_logger - epoch: 3, lr: 6.11e-05 - train loss: 1.39 - valid loss: 1.39, valid f1: 1.00e-01, valid acc: 2.50e-01, valid cm: [[14  0  0  0]\n",
            " [14  0  0  0]\n",
            " [14  0  0  0]\n",
            " [14  0  0  0]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 4\n",
            "speechbrain.nnet.schedulers - Changing lr from 8.3e-05 to 8.5e-05\n",
            "speechbrain.utils.train_logger - epoch: 4, lr: 8.19e-05 - train loss: 1.39 - valid loss: 1.39, valid f1: 1.00e-01, valid acc: 2.50e-01, valid cm: [[ 0  0  0 14]\n",
            " [ 0  0  0 14]\n",
            " [ 0  0  0 14]\n",
            " [ 0  0  0 14]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 5\n",
            "speechbrain.nnet.schedulers - Changing lr from 9.6e-05 to 9.4e-05\n",
            "speechbrain.utils.train_logger - epoch: 5, lr: 9.72e-05 - train loss: 1.39 - valid loss: 1.39, valid f1: 1.00e-01, valid acc: 2.50e-01, valid cm: [[ 0  0  0 14]\n",
            " [ 0  0  0 14]\n",
            " [ 0  0  0 14]\n",
            " [ 0  0  0 14]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 6\n",
            "speechbrain.nnet.schedulers - Changing lr from 7.5e-05 to 7.4e-05\n",
            "speechbrain.utils.train_logger - epoch: 6, lr: 7.64e-05 - train loss: 1.39 - valid loss: 1.39, valid f1: 1.00e-01, valid acc: 2.50e-01, valid cm: [[ 0  0  0 14]\n",
            " [ 0  0  0 14]\n",
            " [ 0  0  0 14]\n",
            " [ 0  0  0 14]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 7\n",
            "speechbrain.nnet.schedulers - Changing lr from 5.4e-05 to 5.3e-05\n",
            "speechbrain.utils.train_logger - epoch: 7, lr: 5.56e-05 - train loss: 1.39 - valid loss: 1.39, valid f1: 1.00e-01, valid acc: 2.50e-01, valid cm: [[ 0  0 14  0]\n",
            " [ 0  0 14  0]\n",
            " [ 0  0 14  0]\n",
            " [ 0  0 14  0]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 8\n",
            "speechbrain.nnet.schedulers - Changing lr from 3.3e-05 to 3.2e-05\n",
            "speechbrain.utils.train_logger - epoch: 8, lr: 3.47e-05 - train loss: 1.39 - valid loss: 1.39, valid f1: 1.00e-01, valid acc: 2.50e-01, valid cm: [[ 0  0 14  0]\n",
            " [ 0  0 14  0]\n",
            " [ 0  0 14  0]\n",
            " [ 0  0 14  0]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 9\n",
            "speechbrain.nnet.schedulers - Changing lr from 1.3e-05 to 1.1e-05\n",
            "speechbrain.utils.train_logger - epoch: 9, lr: 1.39e-05 - train loss: 1.39 - valid loss: 1.39, valid f1: 1.00e-01, valid acc: 2.50e-01, valid cm: [[ 0  0 14  0]\n",
            " [ 0  0 14  0]\n",
            " [ 0  0 14  0]\n",
            " [ 0  0 14  0]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 10\n",
            "speechbrain.nnet.schedulers - Changing lr from 8.3e-06 to 9.7e-06\n",
            "speechbrain.utils.train_logger - epoch: 10, lr: 6.95e-06 - train loss: 1.39 - valid loss: 1.39, valid f1: 1.00e-01, valid acc: 2.50e-01, valid cm: [[ 0  0 14  0]\n",
            " [ 0  0 14  0]\n",
            " [ 0  0 14  0]\n",
            " [ 0  0 14  0]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 11\n",
            "speechbrain.nnet.schedulers - Changing lr from 2.9e-05 to 3.1e-05\n",
            "speechbrain.utils.train_logger - epoch: 11, lr: 2.78e-05 - train loss: 1.39 - valid loss: 1.39, valid f1: 1.00e-01, valid acc: 2.50e-01, valid cm: [[ 0  0 14  0]\n",
            " [ 0  0 14  0]\n",
            " [ 0  0 14  0]\n",
            " [ 0  0 14  0]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 12\n",
            "speechbrain.nnet.schedulers - Changing lr from 5e-05 to 5.1e-05\n",
            "speechbrain.utils.train_logger - epoch: 12, lr: 4.86e-05 - train loss: 1.39 - valid loss: 1.39, valid f1: 1.00e-01, valid acc: 2.50e-01, valid cm: [[ 0  0 14  0]\n",
            " [ 0  0 14  0]\n",
            " [ 0  0 14  0]\n",
            " [ 0  0 14  0]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 13\n",
            "speechbrain.nnet.schedulers - Changing lr from 7.1e-05 to 7.2e-05\n",
            "speechbrain.utils.train_logger - epoch: 13, lr: 6.94e-05 - train loss: 1.39 - valid loss: 1.39, valid f1: 1.00e-01, valid acc: 2.50e-01, valid cm: [[ 0  0 14  0]\n",
            " [ 0  0 14  0]\n",
            " [ 0  0 14  0]\n",
            " [ 0  0 14  0]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 14\n",
            "speechbrain.nnet.schedulers - Changing lr from 9.2e-05 to 9.3e-05\n",
            "speechbrain.utils.train_logger - epoch: 14, lr: 9.03e-05 - train loss: 1.39 - valid loss: 1.39, valid f1: 1.00e-01, valid acc: 2.50e-01, valid cm: [[ 0  0 14  0]\n",
            " [ 0  0 14  0]\n",
            " [ 0  0 14  0]\n",
            " [ 0  0 14  0]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 15\n",
            "speechbrain.nnet.schedulers - Changing lr from 8.8e-05 to 8.6e-05\n",
            "speechbrain.utils.train_logger - epoch: 15, lr: 8.89e-05 - train loss: 1.39 - valid loss: 1.39, valid f1: 1.00e-01, valid acc: 2.50e-01, valid cm: [[ 0  0 14  0]\n",
            " [ 0  0 14  0]\n",
            " [ 0  0 14  0]\n",
            " [ 0  0 14  0]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 16\n",
            "speechbrain.nnet.schedulers - Changing lr from 6.7e-05 to 6.5e-05\n",
            "speechbrain.utils.train_logger - epoch: 16, lr: 6.81e-05 - train loss: 1.39 - valid loss: 1.39, valid f1: 1.00e-01, valid acc: 2.50e-01, valid cm: [[ 0  0 14  0]\n",
            " [ 0  0 14  0]\n",
            " [ 0  0 14  0]\n",
            " [ 0  0 14  0]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 17\n",
            "speechbrain.nnet.schedulers - Changing lr from 4.6e-05 to 4.4e-05\n",
            "speechbrain.utils.train_logger - epoch: 17, lr: 4.72e-05 - train loss: 1.39 - valid loss: 1.39, valid f1: 1.00e-01, valid acc: 2.50e-01, valid cm: [[ 0  0 14  0]\n",
            " [ 0  0 14  0]\n",
            " [ 0  0 14  0]\n",
            " [ 0  0 14  0]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 18\n",
            "speechbrain.nnet.schedulers - Changing lr from 2.5e-05 to 2.4e-05\n",
            "speechbrain.utils.train_logger - epoch: 18, lr: 2.64e-05 - train loss: 1.39 - valid loss: 1.39, valid f1: 1.00e-01, valid acc: 2.50e-01, valid cm: [[ 0  0 14  0]\n",
            " [ 0  0 14  0]\n",
            " [ 0  0 14  0]\n",
            " [ 0  0 14  0]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 19\n",
            "speechbrain.nnet.schedulers - Changing lr from 4.2e-06 to 2.8e-06\n",
            "speechbrain.utils.train_logger - epoch: 19, lr: 5.56e-06 - train loss: 1.39 - valid loss: 1.39, valid f1: 1.00e-01, valid acc: 2.50e-01, valid cm: [[ 0  0 14  0]\n",
            " [ 0  0 14  0]\n",
            " [ 0  0 14  0]\n",
            " [ 0  0 14  0]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 20\n",
            "speechbrain.nnet.schedulers - Changing lr from 1.7e-05 to 1.8e-05\n",
            "speechbrain.utils.train_logger - epoch: 20, lr: 1.53e-05 - train loss: 1.39 - valid loss: 1.39, valid f1: 1.00e-01, valid acc: 2.50e-01, valid cm: [[ 0  0 14  0]\n",
            " [ 0  0 14  0]\n",
            " [ 0  0 14  0]\n",
            " [ 0  0 14  0]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 21\n",
            "speechbrain.nnet.schedulers - Changing lr from 3.8e-05 to 3.9e-05\n",
            "speechbrain.utils.train_logger - epoch: 21, lr: 3.61e-05 - train loss: 1.39 - valid loss: 1.39, valid f1: 1.00e-01, valid acc: 2.50e-01, valid cm: [[ 0  0 14  0]\n",
            " [ 0  0 14  0]\n",
            " [ 0  0 14  0]\n",
            " [ 0  0 14  0]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 22\n",
            "speechbrain.nnet.schedulers - Changing lr from 5.8e-05 to 6e-05\n",
            "speechbrain.utils.train_logger - epoch: 22, lr: 5.69e-05 - train loss: 1.39 - valid loss: 1.39, valid f1: 1.00e-01, valid acc: 2.50e-01, valid cm: [[ 0  0 14  0]\n",
            " [ 0  0 14  0]\n",
            " [ 0  0 14  0]\n",
            " [ 0  0 14  0]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 23\n",
            "speechbrain.nnet.schedulers - Changing lr from 7.9e-05 to 8.1e-05\n",
            "speechbrain.utils.train_logger - epoch: 23, lr: 7.78e-05 - train loss: 1.39 - valid loss: 1.39, valid f1: 1.00e-01, valid acc: 2.50e-01, valid cm: [[ 0  0 14  0]\n",
            " [ 0  0 14  0]\n",
            " [ 0  0 14  0]\n",
            " [ 0  0 14  0]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 24\n",
            "speechbrain.nnet.schedulers - Changing lr from 0.0001 to 9.9e-05\n",
            "speechbrain.utils.train_logger - epoch: 24, lr: 9.86e-05 - train loss: 1.39 - valid loss: 1.39, valid f1: 1.00e-01, valid acc: 2.50e-01, valid cm: [[ 0  0 14  0]\n",
            " [ 0  0 14  0]\n",
            " [ 0  0 14  0]\n",
            " [ 0  0 14  0]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 25\n",
            "speechbrain.nnet.schedulers - Changing lr from 7.9e-05 to 7.8e-05\n",
            "speechbrain.utils.train_logger - epoch: 25, lr: 8.06e-05 - train loss: 1.39 - valid loss: 1.39, valid f1: 1.00e-01, valid acc: 2.50e-01, valid cm: [[ 0  0 14  0]\n",
            " [ 0  0 14  0]\n",
            " [ 0  0 14  0]\n",
            " [ 0  0 14  0]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 26\n",
            "speechbrain.nnet.schedulers - Changing lr from 5.8e-05 to 5.7e-05\n",
            "speechbrain.utils.train_logger - epoch: 26, lr: 5.97e-05 - train loss: 1.39 - valid loss: 1.39, valid f1: 1.00e-01, valid acc: 2.50e-01, valid cm: [[ 0  0 14  0]\n",
            " [ 0  0 14  0]\n",
            " [ 0  0 14  0]\n",
            " [ 0  0 14  0]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 27\n",
            "speechbrain.nnet.schedulers - Changing lr from 3.8e-05 to 3.6e-05\n",
            "speechbrain.utils.train_logger - epoch: 27, lr: 3.89e-05 - train loss: 1.39 - valid loss: 1.39, valid f1: 1.00e-01, valid acc: 2.50e-01, valid cm: [[ 0  0 14  0]\n",
            " [ 0  0 14  0]\n",
            " [ 0  0 14  0]\n",
            " [ 0  0 14  0]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 28\n",
            "speechbrain.nnet.schedulers - Changing lr from 1.7e-05 to 1.5e-05\n",
            "speechbrain.utils.train_logger - epoch: 28, lr: 1.81e-05 - train loss: 1.39 - valid loss: 1.39, valid f1: 1.00e-01, valid acc: 2.50e-01, valid cm: [[ 0  0 14  0]\n",
            " [ 0  0 14  0]\n",
            " [ 0  0 14  0]\n",
            " [ 0  0 14  0]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 29\n",
            "speechbrain.nnet.schedulers - Changing lr from 4.2e-06 to 5.6e-06\n",
            "speechbrain.utils.train_logger - epoch: 29, lr: 2.79e-06 - train loss: 1.39 - valid loss: 1.39, valid f1: 1.00e-01, valid acc: 2.50e-01, valid cm: [[ 0  0 14  0]\n",
            " [ 0  0 14  0]\n",
            " [ 0  0 14  0]\n",
            " [ 0  0 14  0]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 30\n",
            "speechbrain.nnet.schedulers - Changing lr from 2.5e-05 to 2.6e-05\n",
            "speechbrain.utils.train_logger - epoch: 30, lr: 2.36e-05 - train loss: 1.39 - valid loss: 1.39, valid f1: 1.00e-01, valid acc: 2.50e-01, valid cm: [[ 0  0 14  0]\n",
            " [ 0  0 14  0]\n",
            " [ 0  0 14  0]\n",
            " [ 0  0 14  0]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 31\n",
            "speechbrain.nnet.schedulers - Changing lr from 4.6e-05 to 4.7e-05\n",
            "speechbrain.utils.train_logger - epoch: 31, lr: 4.45e-05 - train loss: 1.39 - valid loss: 1.39, valid f1: 1.00e-01, valid acc: 2.50e-01, valid cm: [[ 0  0 14  0]\n",
            " [ 0  0 14  0]\n",
            " [ 0  0 14  0]\n",
            " [ 0  0 14  0]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 32\n",
            "speechbrain.nnet.schedulers - Changing lr from 6.7e-05 to 6.8e-05\n",
            "speechbrain.utils.train_logger - epoch: 32, lr: 6.53e-05 - train loss: 1.39 - valid loss: 1.39, valid f1: 1.00e-01, valid acc: 2.50e-01, valid cm: [[ 0  0 14  0]\n",
            " [ 0  0 14  0]\n",
            " [ 0  0 14  0]\n",
            " [ 0  0 14  0]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 33\n",
            "speechbrain.nnet.schedulers - Changing lr from 8.8e-05 to 8.9e-05\n",
            "speechbrain.utils.train_logger - epoch: 33, lr: 8.61e-05 - train loss: 1.39 - valid loss: 1.39, valid f1: 1.00e-01, valid acc: 2.50e-01, valid cm: [[ 0  0 14  0]\n",
            " [ 0  0 14  0]\n",
            " [ 0  0 14  0]\n",
            " [ 0  0 14  0]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 34\n",
            "speechbrain.core - Patience not yet exhausted.\n",
            "speechbrain.core - Patience not yet exhausted.\n",
            "speechbrain.core - Patience not yet exhausted.\n",
            "speechbrain.core - Exception:\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/benchmarks/benchmarks/MOABB/./train.py\", line 393, in <module>\n",
            "    run_experiment(hparams, run_opts, datasets)\n",
            "  File \"/content/benchmarks/benchmarks/MOABB/./train.py\", line 291, in run_experiment\n",
            "    brain.fit(\n",
            "  File \"/content/speechbrain/speechbrain/core.py\", line 1582, in fit\n",
            "    self._fit_train(train_set=train_set, epoch=epoch, enable=enable)\n",
            "  File \"/content/speechbrain/speechbrain/core.py\", line 1407, in _fit_train\n",
            "    loss = self.fit_batch(batch)\n",
            "  File \"/content/speechbrain/speechbrain/core.py\", line 1207, in fit_batch\n",
            "    self.check_loss_isfinite(scaled_loss)\n",
            "  File \"/content/speechbrain/speechbrain/core.py\", line 1238, in check_loss_isfinite\n",
            "    raise ValueError(\n",
            "ValueError: Loss is not finite and patience is exhausted. To debug, wrap `fit()` with autograd's `detect_anomaly()`, e.g.\n",
            "\n",
            "with torch.autograd.detect_anomaly():\n",
            "\tbrain.fit(...)\n"
          ]
        }
      ]
    }
  ]
}